{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ff02c-e17b-4e94-9063-4fd1519292bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 accelerate einops tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d474ec-8d8e-447d-90b8-4b52fc3d7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "AutoModelForCausalLM,\n",
    "AutoTokenizer,\n",
    "BitsAndBytesConfig,\n",
    "HfArgumentParser,\n",
    "TrainingArguments\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf5deef-235c-4787-a8e7-25dd856a0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import interpreter_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7809aa-e45a-4bf2-95a4-802b78fae0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Token:  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7bfa60f-1436-49e7-afd8-bd8f0f373269",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"tmobley96/black_mirror_scripts_S1-5\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1b2ba3-8d0d-46a6-816f-1412525bd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bab4e1-d0c9-4a27-9d45-b1779e722378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Phone Vibrating)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "0               None\n",
       "1  (Phone Vibrating)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dbfae7b-a6b1-45c4-8e23-7cc2f0543f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17467, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ef9d6c-1c2c-4cd6-aa9d-6e175f2f1ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17467 entries, 0 to 17466\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    17434 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 136.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5715059-2631-4162-8987-dc38fd90a461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Phone Vibrating)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Phone Ringing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why don't you just tell  me what's happened?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17462</th>\n",
       "      <td>Bow down before the one you serve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17463</th>\n",
       "      <td>You're going to get what you deserve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17464</th>\n",
       "      <td>Bow down before the one you serve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17465</th>\n",
       "      <td>You're going to get what you deserve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17466</th>\n",
       "      <td>Bow down before the one you serve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17467 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text\n",
       "0                                              None\n",
       "1                                 (Phone Vibrating)\n",
       "2                                   (Phone Ringing)\n",
       "3                                            Hello?\n",
       "4      Why don't you just tell  me what's happened?\n",
       "...                                             ...\n",
       "17462             Bow down before the one you serve\n",
       "17463          You're going to get what you deserve\n",
       "17464             Bow down before the one you serve\n",
       "17465          You're going to get what you deserve\n",
       "17466             Bow down before the one you serve\n",
       "\n",
       "[17467 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ca3b5-7be4-4a84-8374-aef2165164c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a9ab97-ba79-4c24-95d1-1244e4299d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.text = df.astype(str)\n",
    "df.text.map(len)\n",
    "\n",
    "# Convert the 'text' column to a list of strings\n",
    "df['text'] = df['text'].apply(lambda x: str(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6837d3a1-57d1-4f10-9844-6688c5665db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(Phone, Vibrating)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(Phone, Ringing)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hello?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Why, don't, you, just, tell, me, what's, happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[And, what, is, it?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9392</th>\n",
       "      <td>[[computer, pings]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9393</th>\n",
       "      <td>[-[Vanessa], What's, that?, -[Rasmus], Someone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9394</th>\n",
       "      <td>[-Rasmus?, -I, just, picked, up, an, attempted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>[Granular,, they've, got, a, breach.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>[-[Rasmus], One, ADI, just, went, offline., -W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9364 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "1                                  [(Phone, Vibrating)]\n",
       "2                                    [(Phone, Ringing)]\n",
       "3                                              [Hello?]\n",
       "4     [Why, don't, you, just, tell, me, what's, happ...\n",
       "5                                  [And, what, is, it?]\n",
       "...                                                 ...\n",
       "9392                                [[computer, pings]]\n",
       "9393  [-[Vanessa], What's, that?, -[Rasmus], Someone...\n",
       "9394  [-Rasmus?, -I, just, picked, up, an, attempted...\n",
       "9395              [Granular,, they've, got, a, breach.]\n",
       "9396  [-[Rasmus], One, ADI, just, went, offline., -W...\n",
       "\n",
       "[9364 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(9364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90cf25cc-fb94-47e0-81a5-e5280083d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f04b0d2f-2679-43f2-ac4c-2adfc8d49882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735a0e71c11241168b18466668c9c01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_dataset = load_dataset('csv', data_files=\"data.csv\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c7c13-9c3f-4d4f-94b2-5a3c2156e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(training_dataset)  # Replace with your dataset size\n",
    "num_epochs = 3  # Replace with the number of epochs you plan to use\n",
    "batch_size = 4  # Replace with your batch size\n",
    "\n",
    "max_steps = (dataset_size * num_epochs) // batch_size\n",
    "print(\"Maximum number of training steps:\", max_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78295ff1-0ea2-436b-992a-fd3d56eaaa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec57fb5ca88f4afea7461e96d39b40d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cognitivecomputations/dolphin-2_6-phi-2 were not used when initializing PhiForCausalLM: ['lm_head.linear.lora_A.default.weight', 'lm_head.linear.lora_B.default.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f178f61cc72848e3b18668a4c7cc8e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "base_model = \"cognitivecomputations/dolphin-2_6-phi-2\"\n",
    "new_model = \"dolphin2.6-phi2-black-mirror\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = False\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config = bnb_config,\n",
    "    trust_remote_code = True,\n",
    "    flash_attn = True,\n",
    "    flash_rotary = True,\n",
    "    fused_dense = True,\n",
    "    low_cpu_mem_usage = True,\n",
    "    device_map = {\"\": 0},\n",
    "    #revision = \"refs/pr/23\",\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "model = prepare_model_for_kbit_training(model , use_gradient_checkpointing=True)\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir = \"./black-mirror\",\n",
    "    num_train_epochs = 2,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 32,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps = 1500,\n",
    "    logging_steps = 15,\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    learning_rate = 2e-4,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    save_steps = 1500,\n",
    "    warmup_ratio = 0.05,\n",
    "    weight_decay = 0.01,\n",
    "    max_steps = -1\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r = 32,\n",
    "    lora_alpha = 64,\n",
    "    lora_dropout = 0.05,\n",
    "    bias=\"none\",\n",
    "    task_type = \"CAUSAL_LM\",\n",
    "    target_modules = [\"Wqkv\", \"fcl\", \"fc2\"]\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    train_dataset = training_dataset,\n",
    "    peft_config = peft_config,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 690,\n",
    "    tokenizer = tokenizer,\n",
    "    args = training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61c13bcb-8a5b-4b97-92f0-68835c29ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/544 51:01, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=544, training_loss=3.1753057031070484, metrics={'train_runtime': 3068.1654, 'train_samples_per_second': 11.364, 'train_steps_per_second': 0.177, 'total_flos': 7914059615232000.0, 'train_loss': 3.1753057031070484, 'epoch': 2.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58097331-7eef-49dc-92c6-be8bdb614d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SFTTrainer' object has no attribute 'save_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdolphin2.6-ph2-BlackMirror-2.8b-finetuned-4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#trainer.mode.save_config(\"ph2-BlackMirror-2.8b-finetuned-4bit/config.json\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_config\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdolphin2.6-ph2-BlackMirror-2.8b-finetuned-4bit/config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SFTTrainer' object has no attribute 'save_config'"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"dolphin2.6-ph2-BlackMirror-2.8b-finetuned-4bit\")\n",
    "#trainer.mode.save_config(\"ph2-BlackMirror-2.8b-finetuned-4bit/config.json\")\n",
    "trainer.save_config(\"dolphin2.6-ph2-BlackMirror-2.8b-finetuned-4bit/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaa1df29-5198-4fb3-b3b0-94917f5d7a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36768d729b0540d2a6664dc84e7fad80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/94.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tmobley96/dolphin2.6-phi2-BlackMirror-2.8b-finetuned-4bit/commit/bdb0626a2e59678c4bba60bbf22531e1e34eac1d', commit_message='Fine tuned on Black Mirror transcripts.', commit_description='', oid='bdb0626a2e59678c4bba60bbf22531e1e34eac1d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"tmobley96/dolphin2.6-phi2-BlackMirror-2.8b-finetuned-4bit\",\n",
    "                  use_auth_token=True,\n",
    "                  commit_message=\"Fine tuned on Black Mirror transcripts.\",\n",
    "                  private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc0b3b4d-ca65-49fc-937f-1f759234eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Loading cognitivecomputations/dolphin-2_6-phi-2 requires to execute some code in that repo, you can inspect the content of the repository at https://hf.co/cognitivecomputations/dolphin-2_6-phi-2. You can dismiss this prompt by passing `trust_remote_code=True`.\n",
      "Do you accept? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f52a7e4f4904a2c9d8e66fd249a44f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cognitivecomputations/dolphin-2_6-phi-2 were not used when initializing PhiForCausalLM: ['lm_head.linear.lora_A.default.weight', 'lm_head.linear.lora_B.default.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"dolphin2.6-ph2-BlackMirror-2.8b-finetuned-4bit\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=True, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Loading the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65c4dc69-d654-41c3-82ac-3501d0bf6102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " “Training models with PEFT and LoRa is cool” ->: \\'s\",', \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you',\", \"'you\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer(\"“Training models with PEFT and LoRa is cool” ->: \", return_tensors='pt')\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "  output_tokens = model.generate(**batch, max_new_tokens=50)\n",
    "\n",
    "print('\\n\\n', tokenizer.decode(output_tokens[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7e0a3-d9bd-4c1d-81fe-d9b9fc99bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34712214-3bd9-42dc-9ce7-788f72db1dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f766ad4-bf4b-46c4-bac2-7e860ccbfc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf49135-9102-4820-a605-b46d4c5fd893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bb949-a5cf-47f0-9022-514d47d18856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8be5f-c6f7-494f-b02f-de2a2f78fa62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7979b5-7d2e-4840-b021-96fb162b4aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
